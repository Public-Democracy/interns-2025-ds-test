{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Test: Chatbot Conversation Analysis\n",
    "\n",
    "### Overview\n",
    "In this technical test, you'll be working with a dataset of conversations. Your task is to analyze this dataset, extract key metrics, and create visualizations.\n",
    "\n",
    "### Tasks\n",
    "1. Load and explore the dataset\n",
    "2. Find the longest and shortest conversations\n",
    "3. Create a histogram of conversation lengths\n",
    "4. Find the most common words (excluding stopwords)\n",
    "5. Find the longest word in the dataset\n",
    "6. Create at least one additional visualization of your choice\n",
    "\n",
    "### Evaluation Criteria\n",
    "- Correct implementation of all tasks\n",
    "- Code efficiency and readability\n",
    "- Quality of visualizations\n",
    "- Insights derived from the analysis\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Load and explore the dataset\n",
    "Load the dataset and display basic information about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "# Download NLTK stopwords\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the dataset 'conversations.csv'\n",
    "# Display the first few rows of the dataset\n",
    "# Display basic information about the dataset (shape, data types)\n",
    "# Calculate and print the number of unique conversations and total messages\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Find the longest and shortest conversations\n",
    "Identify which conversations have the most and least number of messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate the number of messages in each conversation\n",
    "# Find and print details about the longest conversation\n",
    "# Find and print details about the shortest conversation\n",
    "# Calculate and print the average conversation length\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Create a histogram of conversation lengths\n",
    "Visualize the distribution of conversation lengths (number of messages per conversation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a histogram showing the distribution of conversation lengths\n",
    "# Make sure to include appropriate labels and title\n",
    "# Add a grid for better readability\n",
    "# Save the figure as 'conversation_length_histogram.png'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Find the most common words\n",
    "Extract all words from the conversations and identify the most frequently used words (excluding common stopwords)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract all words from the 'content' column\n",
    "# Remove stopwords using NLTK\n",
    "# Find and print the 10 most common words and their frequencies\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Find the longest word\n",
    "Identify the longest word used in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find the longest word in the dataset\n",
    "# Print the word and its length\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Create an additional visualization\n",
    "Create at least one more visualization that provides insights into the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Task 6: Creating an additional visualization - Response Time Analysis\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# First, let's load the data if it hasn't been loaded already\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlocals\u001b[39m():\n\u001b[0;32m----> 5\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../chatbot_conversations.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Convert timestamp to datetime format\u001b[39;00m\n\u001b[1;32m      8\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: Create an additional visualization of your choice\n",
    "# Some ideas:\n",
    "# - Bar chart of most common words\n",
    "# - Message distribution by role (user vs. assistant)\n",
    "# - Average message length by role\n",
    "# - Word cloud of most frequent terms\n",
    "# - Any other visualization that provides interesting insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus (if time permits): Additional Analysis\n",
    "If you have time remaining, try to extract additional insights from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus: Perform additional analysis of your choice\n",
    "# Some ideas:\n",
    "# - Sentiment analysis of messages\n",
    "# - Identify conversations with questions (messages containing '?')\n",
    "# - Compare vocabulary richness between roles\n",
    "# - Analyze time patterns\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "technical_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
